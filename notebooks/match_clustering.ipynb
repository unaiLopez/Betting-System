{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../inputs/ready_data/preprocessed_all_matches.csv', parse_dates=['Date'])\n",
    "df.dropna(subset=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "df = df[['Full_Time_Result', 'Home Overall Score', 'Home Attack Score', 'Home Middle Score', 'Home Defensive Score', 'Home Budget',\n",
    "        'Away Overall Score', 'Away Attack Score', 'Away Middle Score', 'Away Defensive Score', 'Away Budget', 'Difference_Overall_Score',\n",
    "        'Difference_Attack_Score', 'Difference_Middle_Score', 'Difference_Defensive_Score', 'Difference_Budget', 'HOME_TRUESKILL_MU_NO_RESET',\n",
    "        'AWAY_TRUESKILL_MU_NO_RESET','HOME_TRUESKILL_SIGMA_NO_RESET', 'AWAY_TRUESKILL_SIGMA_NO_RESET','DRAW_CHANCE_NO_RESET',\n",
    "        'HOME_TRUESKILL_MU_SEASON', 'AWAY_TRUESKILL_MU_SEASON', 'HOME_TRUESKILL_SIGMA_SEASON', 'AWAY_TRUESKILL_SIGMA_SEASON',\n",
    "        'DRAW_CHANCE_SEASON', 'HOME_ID', 'AWAY_ID',\n",
    "        'HOME_WINS_HOME', 'HOME_DRAWS_HOME', 'HOME_LOSSES_HOME', 'AWAY_WINS_HOME', 'AWAY_DRAWS_HOME', 'AWAY_LOSSES_HOME', 'HOME_WINS_AWAY', 'HOME_DRAWS_AWAY', \n",
    "        'HOME_LOSSES_AWAY', 'AWAY_WINS_AWAY', 'AWAY_DRAWS_AWAY', 'AWAY_LOSSES_AWAY']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = []\n",
    "K = range(1,8)\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k)\n",
    "    kmeanModel.fit(df)\n",
    "    distortions.append(kmeanModel.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5210"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['Full_Time_Result'], axis=1)\n",
    "y = df.Full_Time_Result\n",
    "\n",
    "kmeanModel = KMeans(n_clusters=10)\n",
    "kmeanModel.fit(X)\n",
    "kmeanModel.labels_\n",
    "len(kmeanModel.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full_Time_Result</th>\n",
       "      <th>Home Overall Score</th>\n",
       "      <th>Home Attack Score</th>\n",
       "      <th>Home Middle Score</th>\n",
       "      <th>Home Defensive Score</th>\n",
       "      <th>Home Budget</th>\n",
       "      <th>Away Overall Score</th>\n",
       "      <th>Away Attack Score</th>\n",
       "      <th>Away Middle Score</th>\n",
       "      <th>Away Defensive Score</th>\n",
       "      <th>...</th>\n",
       "      <th>AWAY_WINS_HOME</th>\n",
       "      <th>AWAY_DRAWS_HOME</th>\n",
       "      <th>AWAY_LOSSES_HOME</th>\n",
       "      <th>HOME_WINS_AWAY</th>\n",
       "      <th>HOME_DRAWS_AWAY</th>\n",
       "      <th>HOME_LOSSES_AWAY</th>\n",
       "      <th>AWAY_WINS_AWAY</th>\n",
       "      <th>AWAY_DRAWS_AWAY</th>\n",
       "      <th>AWAY_LOSSES_AWAY</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>83</td>\n",
       "      <td>80</td>\n",
       "      <td>78</td>\n",
       "      <td>25.0</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>74</td>\n",
       "      <td>73</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>75</td>\n",
       "      <td>74</td>\n",
       "      <td>73</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>74</td>\n",
       "      <td>72</td>\n",
       "      <td>15.0</td>\n",
       "      <td>72</td>\n",
       "      <td>75</td>\n",
       "      <td>70</td>\n",
       "      <td>68</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>72</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>8.0</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>80</td>\n",
       "      <td>76</td>\n",
       "      <td>73</td>\n",
       "      <td>7.5</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5205</th>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "      <td>74</td>\n",
       "      <td>73</td>\n",
       "      <td>4.4</td>\n",
       "      <td>77</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5206</th>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>73</td>\n",
       "      <td>3.1</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5207</th>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>76</td>\n",
       "      <td>8.2</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5208</th>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>79</td>\n",
       "      <td>78</td>\n",
       "      <td>32.9</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5209</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>78</td>\n",
       "      <td>16.1</td>\n",
       "      <td>86</td>\n",
       "      <td>85</td>\n",
       "      <td>87</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5210 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Full_Time_Result  Home Overall Score  Home Attack Score  \\\n",
       "0                    1                  81                 83   \n",
       "1                    0                  76                 75   \n",
       "2                    2                  76                 78   \n",
       "3                    1                  75                 72   \n",
       "4                    2                  78                 80   \n",
       "...                ...                 ...                ...   \n",
       "5205                 2                  74                 76   \n",
       "5206                 0                  76                 76   \n",
       "5207                 2                  77                 77   \n",
       "5208                 1                  79                 80   \n",
       "5209                 2                  80                 81   \n",
       "\n",
       "      Home Middle Score  Home Defensive Score  Home Budget  \\\n",
       "0                    80                    78         25.0   \n",
       "1                    74                    73          1.0   \n",
       "2                    74                    72         15.0   \n",
       "3                    75                    75          8.0   \n",
       "4                    76                    73          7.5   \n",
       "...                 ...                   ...          ...   \n",
       "5205                 74                    73          4.4   \n",
       "5206                 76                    73          3.1   \n",
       "5207                 77                    76          8.2   \n",
       "5208                 79                    78         32.9   \n",
       "5209                 81                    78         16.1   \n",
       "\n",
       "      Away Overall Score  Away Attack Score  Away Middle Score  \\\n",
       "0                     76                 76                 74   \n",
       "1                     72                 72                 72   \n",
       "2                     72                 75                 70   \n",
       "3                     76                 78                 77   \n",
       "4                     74                 74                 74   \n",
       "...                  ...                ...                ...   \n",
       "5205                  77                 78                 78   \n",
       "5206                  79                 79                 79   \n",
       "5207                  75                 76                 75   \n",
       "5208                  75                 75                 75   \n",
       "5209                  86                 85                 87   \n",
       "\n",
       "      Away Defensive Score  ...  AWAY_WINS_HOME  AWAY_DRAWS_HOME  \\\n",
       "0                       73  ...               0                0   \n",
       "1                       70  ...               0                0   \n",
       "2                       68  ...               0                0   \n",
       "3                       72  ...               0                0   \n",
       "4                       74  ...               0                0   \n",
       "...                    ...  ...             ...              ...   \n",
       "5205                    76  ...               7                3   \n",
       "5206                    79  ...               8                2   \n",
       "5207                    75  ...               4                3   \n",
       "5208                    75  ...               9                4   \n",
       "5209                    85  ...               8                2   \n",
       "\n",
       "      AWAY_LOSSES_HOME  HOME_WINS_AWAY  HOME_DRAWS_AWAY  HOME_LOSSES_AWAY  \\\n",
       "0                    0               0                0                 0   \n",
       "1                    0               0                0                 0   \n",
       "2                    0               0                0                 0   \n",
       "3                    0               0                0                 0   \n",
       "4                    0               0                0                 0   \n",
       "...                ...             ...              ...               ...   \n",
       "5205                 3               3                4                 7   \n",
       "5206                 3               3                0                11   \n",
       "5207                 7               5                1                 8   \n",
       "5208                 0               1                6                 6   \n",
       "5209                 3               1                5                 7   \n",
       "\n",
       "      AWAY_WINS_AWAY  AWAY_DRAWS_AWAY  AWAY_LOSSES_AWAY  Cluster  \n",
       "0                  0                0                 0        3  \n",
       "1                  0                0                 0        9  \n",
       "2                  0                0                 0        3  \n",
       "3                  0                0                 0        9  \n",
       "4                  0                0                 0        9  \n",
       "...              ...              ...               ...      ...  \n",
       "5205               1                7                 5        0  \n",
       "5206               3                2                 8        8  \n",
       "5207               0                5                 7        9  \n",
       "5208               7                4                 2        3  \n",
       "5209               5                2                 6        7  \n",
       "\n",
       "[5210 rows x 41 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cluster'] = kmeanModel.labels_\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5302325581395348"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.33, shuffle=False)\n",
    "model = SVC()   \n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 9, 1, 5, 8, 6, 0, 2, 4, 7], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Cluster.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cluster  Full_Time_Result\n",
       "0        1                   419\n",
       "         2                   287\n",
       "         0                   260\n",
       "1        1                   300\n",
       "         0                    27\n",
       "         2                    14\n",
       "2        2                    20\n",
       "         0                    19\n",
       "         1                    19\n",
       "3        1                   474\n",
       "         0                   153\n",
       "         2                   113\n",
       "4        1                    47\n",
       "         0                     9\n",
       "         2                     5\n",
       "5        2                   329\n",
       "         0                   114\n",
       "         1                   103\n",
       "6        1                   162\n",
       "         0                    48\n",
       "         2                    24\n",
       "7        2                    31\n",
       "         0                    16\n",
       "         1                    14\n",
       "8        2                   290\n",
       "         1                   263\n",
       "         0                   181\n",
       "9        1                   695\n",
       "         0                   422\n",
       "         2                   352\n",
       "Name: Full_Time_Result, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Cluster').Full_Time_Result.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "def get_best_model(df_clust: pd.DataFrame, full_df: pd.DataFrame):\n",
    "    models = ['SVM', 'RF', 'LR', 'XGB', 'KNN', 'SGD']\n",
    "    best_acc = 0\n",
    "    best_precision = 0\n",
    "    best_recall = 0\n",
    "    best_fscore = 0\n",
    "    best_support = 0\n",
    "    best_model = 'None'\n",
    "\n",
    "    for model_name in models:\n",
    "        X = full_df.drop(['Full_Time_Result'], axis=1)\n",
    "        column_names = X.columns\n",
    "        y = full_df.Full_Time_Result\n",
    "        if model_name == 'SVM':\n",
    "            model = SVC(random_state=42)\n",
    "            X = StandardScaler().fit_transform(X)\n",
    "        elif model_name == 'LR':\n",
    "            model = LogisticRegression()\n",
    "            X = StandardScaler().fit_transform(X)\n",
    "        elif model_name == 'XGB':\n",
    "            model = XGBClassifier(random_state=42, verbosity=0)\n",
    "\n",
    "        elif model_name == 'RF':\n",
    "            model = RandomForestClassifier(random_state=42)\n",
    "        \n",
    "        elif model_name == 'SGD':\n",
    "            model = LogisticRegression(random_state=42)\n",
    "            X = StandardScaler().fit_transform(X)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "\n",
    "        y_train_merge = pd.DataFrame({'Full_Time_Result': y_train})\n",
    "        X_train_merge = pd.DataFrame(columns=column_names, data=X_train)\n",
    "        train = pd.concat([X_train_merge, y_train_merge], axis=1)\n",
    "\n",
    "        # print(df_clust.shape, train.shape)\n",
    "        df_clust = df_clust.astype(train.dtypes.to_dict())\n",
    "        train = pd.merge(df_clust, train, how='outer', indicator='Exist')\n",
    "        train = train.loc[train['Exist'] != 'both']\n",
    "        train = train.dropna(subset=['Cluster', 'Full_Time_Result'])\n",
    "        X_train_merge = train.drop(['Full_Time_Result', 'Exist'], axis=1)\n",
    "        y_train_merge = train.Full_Time_Result\n",
    "        # print('SHAPES: ', X_train.shape, y_train.shape)\n",
    "        # print('NA Count: ', X_train_merge.isna().sum().sum(), y_train_merge.isna().sum())\n",
    "\n",
    "        model.fit(X_train_merge.values, y_train_merge.values)\n",
    "        y_pred = model.predict(df_clust.drop(['Full_Time_Result'], axis=1))\n",
    "        y_test = df_clust.Full_Time_Result\n",
    "        \n",
    "        aux_acc = accuracy_score(y_test, y_pred)\n",
    "        aux_precision, aux_recall, aux_fscore, aux_support = score(y_test, y_pred)\n",
    "        if best_acc < aux_acc:\n",
    "            best_model = model_name\n",
    "            best_acc = aux_acc\n",
    "            mod_precision = aux_precision\n",
    "            mod_recall = aux_recall\n",
    "            mod_fscore = aux_fscore\n",
    "            mod_support = aux_support\n",
    "\n",
    "    return best_acc, best_model, mod_precision, mod_recall, mod_fscore, mod_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_models_per_cluster(df: pd.DataFrame):\n",
    "    model_final_df = pd.DataFrame({'Cluster': [], 'Best_Model': [], 'Best_Acc': [], \n",
    "                                   'Home_Wins': [], 'Draws': [], 'Away_Wins': [],\n",
    "                                   'Total_Matches': []})\n",
    "    for cluster_numb in tqdm(df.Cluster.unique()):\n",
    "        model_df = df.query('Cluster == @cluster_numb')\n",
    "        \n",
    "        home_wins = model_df.query('Full_Time_Result == 1').count().Full_Time_Result\n",
    "        draws = model_df.query('Full_Time_Result == 0').count().Full_Time_Result\n",
    "        away_wins = model_df.query('Full_Time_Result == 2').count().Full_Time_Result\n",
    "        total_matches = model_df.shape[0]\n",
    "        best_model = None\n",
    "        best_acc = 0\n",
    "        best_acc, best_model, mod_precision, mod_recall, mod_fscore, mod_support = get_best_model(model_df, df)\n",
    "        print(\"Best model for cluster {} was {} with an accuracy of {}\".format(cluster_numb, best_model, best_acc))\n",
    "        model_final_df = model_final_df.append({'Cluster': cluster_numb, 'Best_Model': best_model, \n",
    "                                                'Best_Acc': best_acc, 'Model_Precision': mod_precision,\n",
    "                                                'Model_Recall': mod_recall, 'Model_FScore': mod_fscore,\n",
    "                                                'Model_Support': mod_support, 'Home_Wins': home_wins,\n",
    "                                                'Draws': draws, 'Away_Wins': away_wins, 'Total_Matches': total_matches}\n",
    "                                                , ignore_index=True)\n",
    "    return model_final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:06<00:54,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for cluster 3 was RF with an accuracy of 0.7067567567567568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:12<00:49,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for cluster 9 was XGB with an accuracy of 0.5643294758339006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:19<00:47,  6.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for cluster 1 was RF with an accuracy of 0.9002932551319648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:28<00:46,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for cluster 5 was RF with an accuracy of 0.6721611721611722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:37<00:40,  8.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for cluster 8 was KNN with an accuracy of 0.5204359673024523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:44<00:30,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for cluster 6 was RF with an accuracy of 0.7521367521367521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:51<00:22,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for cluster 0 was RF with an accuracy of 0.5124223602484472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:58<00:14,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for cluster 2 was SVM with an accuracy of 0.5862068965517241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [01:06<00:07,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for cluster 4 was XGB with an accuracy of 0.8360655737704918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:14<00:00,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for cluster 7 was SGD with an accuracy of 0.5901639344262295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = get_best_models_per_cluster(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Cluster'] = data['Cluster'].astype('int')\n",
    "data['Home_Wins'] = data['Home_Wins'].astype('int')\n",
    "data['Away_Wins'] = data['Away_Wins'].astype('int')\n",
    "data['Draws'] = data['Draws'].astype('int')\n",
    "data['Total_Matches'] = data['Total_Matches'].astype('int')\n",
    "data['Home_Wins_Percentage'] = data['Home_Wins'] / data['Total_Matches']\n",
    "data['Draws_Percentage'] = data['Draws'] / data['Total_Matches']\n",
    "data['Away_Wins_Percentage'] = data['Away_Wins'] / data['Total_Matches']\n",
    "data['Weight'] = data['Total_Matches'] / data.Total_Matches.sum()\n",
    "data_metrics = data.drop(['Model_Support', 'Model_FScore', 'Model_Precision'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Best_Model</th>\n",
       "      <th>Best_Acc</th>\n",
       "      <th>Recall_Home</th>\n",
       "      <th>Recall_Draw</th>\n",
       "      <th>Recall_Away</th>\n",
       "      <th>Home_Wins_Percentage</th>\n",
       "      <th>Draws_Percentage</th>\n",
       "      <th>Away_Wins_Percentage</th>\n",
       "      <th>Total_Matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.08</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.10</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.15</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.60</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.34</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.51</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.40</td>\n",
       "      <td>734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.30</td>\n",
       "      <td>966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cluster Best_Model  Best_Acc  Recall_Home  Recall_Draw  Recall_Away  \\\n",
       "2        1         RF      0.90         1.00         0.19         0.14   \n",
       "8        4        XGB      0.84         0.98         0.22         0.60   \n",
       "5        6         RF      0.75         0.98         0.27         0.21   \n",
       "0        3         RF      0.71         0.99         0.20         0.21   \n",
       "3        5         RF      0.67         0.46         0.22         0.90   \n",
       "7        2        SVM      0.59         0.79         0.58         0.40   \n",
       "9        7        SGD      0.59         0.29         0.31         0.87   \n",
       "1        9        XGB      0.56         0.84         0.35         0.27   \n",
       "4        8        KNN      0.52         0.68         0.31         0.50   \n",
       "6        0         RF      0.51         0.73         0.39         0.30   \n",
       "\n",
       "   Home_Wins_Percentage  Draws_Percentage  Away_Wins_Percentage  Total_Matches  \n",
       "2                  0.88              0.08                  0.04            341  \n",
       "8                  0.77              0.15                  0.08             61  \n",
       "5                  0.69              0.21                  0.10            234  \n",
       "0                  0.64              0.21                  0.15            740  \n",
       "3                  0.19              0.21                  0.60            546  \n",
       "7                  0.33              0.33                  0.34             58  \n",
       "9                  0.23              0.26                  0.51             61  \n",
       "1                  0.47              0.29                  0.24           1469  \n",
       "4                  0.36              0.25                  0.40            734  \n",
       "6                  0.43              0.27                  0.30            966  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_metrics[['Recall_Draw',  'Recall_Home', 'Recall_Away']]=data_metrics.Model_Recall.apply(pd.Series)\n",
    "data_metrics = data_metrics.round(2)\n",
    "data_metrics.sort_values(by='Best_Acc', ascending=False)[['Cluster', 'Best_Model', 'Best_Acc', 'Recall_Home', 'Recall_Draw', \n",
    "                                                          'Recall_Away', 'Home_Wins_Percentage', 'Draws_Percentage', 'Away_Wins_Percentage', 'Total_Matches']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.420345489443385"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data['Best_Acc'] * 100 * data['Weight']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52965116, 0.53662791, 0.52965116, 0.52906977, 0.52790698])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../inputs/ready_data/preprocessed_all_matches.csv', parse_dates=['Date'])\n",
    "df.dropna(subset=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "df = df[['Full_Time_Result', 'Home Overall Score', 'Home Attack Score', 'Home Middle Score', 'Home Defensive Score', 'Home Budget',\n",
    "        'Away Overall Score', 'Away Attack Score', 'Away Middle Score', 'Away Defensive Score', 'Away Budget', 'Difference_Overall_Score',\n",
    "        'Difference_Attack_Score', 'Difference_Middle_Score', 'Difference_Defensive_Score', 'Difference_Budget', 'HOME_TRUESKILL_MU_NO_RESET',\n",
    "        'AWAY_TRUESKILL_MU_NO_RESET','HOME_TRUESKILL_SIGMA_NO_RESET', 'AWAY_TRUESKILL_SIGMA_NO_RESET','DRAW_CHANCE_NO_RESET',\n",
    "        'HOME_TRUESKILL_MU_SEASON', 'AWAY_TRUESKILL_MU_SEASON', 'HOME_TRUESKILL_SIGMA_SEASON', 'AWAY_TRUESKILL_SIGMA_SEASON',\n",
    "        'DRAW_CHANCE_SEASON', 'HOME_ID', 'AWAY_ID',\n",
    "        'HOME_WINS_HOME', 'HOME_DRAWS_HOME', 'HOME_LOSSES_HOME', 'AWAY_WINS_HOME', 'AWAY_DRAWS_HOME', 'AWAY_LOSSES_HOME', 'HOME_WINS_AWAY', 'HOME_DRAWS_AWAY', \n",
    "        'HOME_LOSSES_AWAY', 'AWAY_WINS_AWAY', 'AWAY_DRAWS_AWAY', 'AWAY_LOSSES_AWAY']]\n",
    "\n",
    "v_G = np.linspace(11,51,5,dtype=int)\n",
    "\n",
    "acierto_bagging = np.empty(len(v_G))\n",
    "coste_bagging = np.empty(len(v_G))\n",
    "v_max_samples = np.empty(len(v_G))\n",
    "dict_bagging = {}\n",
    "\n",
    "X = df.drop(['Full_Time_Result'], axis=1)\n",
    "y = df.Full_Time_Result\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "for i,K in enumerate(v_G):\n",
    "   \n",
    "    max_samples = int(X_train.shape[0] / K)\n",
    "    v_max_samples[i] = max_samples\n",
    "   \n",
    "    bc = BaggingClassifier(base_estimator = SVC(), n_estimators = K, max_samples = max_samples).fit(X_train, y_train)\n",
    "    dict_bagging[K] = bc\n",
    "    acierto_bagging[i] = bc.score(X_test,y_test)\n",
    "    # coste_bagging[i] = K * interpolar_tiempo_svm(max_samples)\n",
    "\n",
    "acierto_bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mol/Escritorio/Proyectos/Betting-System/venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mol/Escritorio/Proyectos/Betting-System/venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.538953488372093\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../inputs/ready_data/preprocessed_all_matches.csv', parse_dates=['Date'])\n",
    "df.dropna(subset=['HomeTeam', 'AwayTeam'], inplace=True)\n",
    "df = df[['Full_Time_Result', 'Home Overall Score', 'Home Attack Score', 'Home Middle Score', 'Home Defensive Score', 'Home Budget',\n",
    "        'Away Overall Score', 'Away Attack Score', 'Away Middle Score', 'Away Defensive Score', 'Away Budget', 'Difference_Overall_Score',\n",
    "        'Difference_Attack_Score', 'Difference_Middle_Score', 'Difference_Defensive_Score', 'Difference_Budget', 'HOME_TRUESKILL_MU_NO_RESET',\n",
    "        'AWAY_TRUESKILL_MU_NO_RESET','HOME_TRUESKILL_SIGMA_NO_RESET', 'AWAY_TRUESKILL_SIGMA_NO_RESET','DRAW_CHANCE_NO_RESET',\n",
    "        'HOME_TRUESKILL_MU_SEASON', 'AWAY_TRUESKILL_MU_SEASON', 'HOME_TRUESKILL_SIGMA_SEASON', 'AWAY_TRUESKILL_SIGMA_SEASON',\n",
    "        'DRAW_CHANCE_SEASON', 'HOME_ID', 'AWAY_ID',\n",
    "        'HOME_WINS_HOME', 'HOME_DRAWS_HOME', 'HOME_LOSSES_HOME', 'AWAY_WINS_HOME', 'AWAY_DRAWS_HOME', 'AWAY_LOSSES_HOME', 'HOME_WINS_AWAY', 'HOME_DRAWS_AWAY', \n",
    "        'HOME_LOSSES_AWAY', 'AWAY_WINS_AWAY', 'AWAY_DRAWS_AWAY', 'AWAY_LOSSES_AWAY']]\n",
    "\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(random_state=42)),\n",
    "    ('svc', make_pipeline(StandardScaler(), SVC(random_state=42))),\n",
    "    ('lr', make_pipeline(StandardScaler(),LogisticRegression(random_state=42, max_iter=500))),\n",
    "    ('xgb', XGBClassifier(eval_metric='mlogloss', use_label_encoder=False))\n",
    "]\n",
    "\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "X = df.drop(['Full_Time_Result'], axis=1)\n",
    "y = df.Full_Time_Result\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42, test_size=0.33)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.fit(X_train, y_train).score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "53faabe0e0345219f91441a5e627a878968927929e4459b9887e4068c65a2fdc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
